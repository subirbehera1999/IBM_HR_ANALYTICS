# Employee Attrition Prediction â€“ Production-Ready ML Pipeline

## ğŸ”— Live Deployment
**API Endpoint:**  
- Root Link: *https://ibm-hr-analytics.onrender.com*
- Testing Link: *https://ibm-hr-analytics.onrender.com/docs*
- Endpoint Link: *https://ibm-hr-analytics.onrender.com/predict*

---

## ğŸ“Œ Project Overview

Employee attrition is a critical HR problem where **missing a potential resignation is more costly than raising a false alert**.  
This project builds an **end-to-end, deployment-ready machine learning pipeline** to predict employee attrition using structured HR data.

The focus of this project is not only model accuracy, but:
- Handling class imbalance correctly
- Building honest probability estimates
- Selecting an optimal decision threshold
- Designing a pipeline safe for production deployment

---

## ğŸ“Š Dataset Summary

- Total records: **1470**
- Target variable: **Attrition**
  - `Yes`: 237 (~16%)
  - `No`: 1233 (~84%)

This is a **highly imbalanced binary classification problem**, where accuracy alone is misleading.

---

## ğŸ§© Feature Categorization & Handling

### 1ï¸âƒ£ Categorical (Nominal)
BusinessTravel, Department, EducationField, Gender,
JobRole, MaritalStatus, OverTime


**Handling:**
- One-Hot Encoding
- `drop="first"` to avoid multicollinearity
- `handle_unknown="ignore"` for deployment safety

---

### 2ï¸âƒ£ Ordinal Features
Education, EnvironmentSatisfaction, JobInvolvement,
JobSatisfaction, PerformanceRating, RelationshipSatisfaction,
WorkLifeBalance, JobLevel, StockOptionLevel


**Decision:**
- Kept as numeric (ordering is meaningful)
- No one-hot encoding applied
- Scaled along with numeric features

---

### 3ï¸âƒ£ Numeric (Continuous)
Age, MonthlyIncome, TotalWorkingYears, YearsAtCompany,
YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager, etc.


**Outlier Handling Decision:**
- Outliers are **true business values**, not data errors
- Rows were **not dropped**
- Values were **not capped**
- Used **RobustScaler** to reduce outlier influence safely

---

## ğŸ”§ Preprocessing Pipeline

All preprocessing is handled using a single `ColumnTransformer`:

- OneHotEncoder â†’ categorical features
- RobustScaler â†’ numeric + ordinal features

This ensures:
- No data leakage
- Consistent behavior during inference
- Clean deployment with serialized pipeline

---

## ğŸ¤– Model Selection

### Logistic Regression (Baseline Model)

Chosen because:
- Interpretable
- Stable
- Strong baseline for tabular HR data
- Works well with calibrated probabilities

**Configuration:**
- `class_weight="balanced"`
- `solver="liblinear"`
- `max_iter=1000`

---

## ğŸ§ª Train / Validation / Test Split

- Train: **70%**
- Validation: **15%**
- Test: **15%**

**Stratified splitting** was used to preserve class distribution.

### Why Validation Data?
- Probability calibration
- Threshold selection
- Prevents optimistic bias
- Ensures honest evaluation

---

## ğŸ¯ Probability Calibration

Raw model probabilities are often **over-confident**, especially in imbalanced datasets.

**Solution:**
- `CalibratedClassifierCV` with **Isotonic Regression**
- Model trained on training data
- Calibration learned on validation data

This ensures:
- Reliable probabilities
- Stable threshold behavior in production

---

## ğŸ”¢ Threshold Selection Strategy (F1-Score Based)

### Why threshold tuning is required
- Default threshold (0.5) is rarely optimal for imbalanced data
- Business requires a balance between:
  - Capturing attrition cases (Recall)
  - Avoiding excessive false alerts (Precision)

### Final Decision
The decision threshold was selected by **maximizing the F1-score** on the validation set.

**Reason:**
- F1-score provides a balanced trade-off between precision and recall
- Simple, interpretable, and commonly accepted baseline strategy
- Suitable when explicit business costs are not yet defined

---

## ğŸ“ˆ Model Performance (Test Set)

**Attrition = Yes (Positive Class):**

- Recall â‰ˆ **0.69**
- Precision â‰ˆ **0.41**
- F1-score â‰ˆ **0.52**

**Overall Accuracy:** â‰ˆ **0.79**

These results are:
- Realistic for HR attrition data
- Achieved without data leakage
- Stable after calibration and threshold tuning

---

## ğŸš€ Deployment Details

- Entire pipeline (preprocessing + model) is serialized
- Final model returns:
  - `1` â†’ Attrition risk
  - `0` â†’ No attrition risk
- Integrated with FastAPI for real-time inference
- Ready for production usage

---

## âœ… Key Design Principles Followed

- No data leakage
- Honest probability estimation
- Proper handling of class imbalance
- Pipeline-based preprocessing
- Threshold-aware decision making
- Deployment-safe architecture

---

## ğŸ”® Future Improvements

- Business cost-based threshold optimization
- Gradient Boosting / Tree-based models
- Model monitoring & drift detection
- Explainability (SHAP)
- Feedback loop from HR outcomes

---

## ğŸ“ Final Note

This project prioritizes **decision quality over metric chasing**.  
The goal is to build a model that behaves **reliably in real-world conditions**, not just one that performs well on paper.

---

## ğŸ‘¤ Author
### Subir Kumar Behera
Aspiring Data Analyst | Machine Learning Enthusiast

